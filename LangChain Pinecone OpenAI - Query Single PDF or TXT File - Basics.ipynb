{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb10631",
   "metadata": {},
   "source": [
    "# LangChain Pinecone OpenAI - Query Your Own Text/PDF File - The Basics\n",
    "\n",
    "#### This notebook walks through the basics of using Pinecone, OpenAI and LangChain to query your own text document \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0fc55",
   "metadata": {},
   "source": [
    "## pip install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccdca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c679b5",
   "metadata": {},
   "source": [
    "### Set environment variables and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24cdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEYS, MODELS and ENV Related Settings \n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"\"\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_ENV = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81cc94",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf868f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, langchain, pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64b8ec",
   "metadata": {},
   "source": [
    "### Import your own text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0efff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227191"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the data file and read its content\n",
    "\n",
    "file_data = open('../data/WizardOfOz.txt', 'r')\n",
    "file_content = file_data.read()\n",
    "len(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b84d9",
   "metadata": {},
   "source": [
    "### Split the text using RecursiveCharacterTextSplitter to be able to work with the 4096 OpenAI token limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d3f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b197f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the file content \n",
    "\n",
    "book_texts = text_splitter.create_documents([file_content])\n",
    "print (len(book_texts))\n",
    "type(book_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b0c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='But the Lion went away into the forest and found his own supper, and no\\none ever knew what it was, for he didn’t mention it. And the Scarecrow\\nfound a tree full of nuts and filled Dorothy’s basket with them, so\\nthat she would not be hungry for a long time. She thought this was very\\nkind and thoughtful of the Scarecrow, but she laughed heartily at the\\nawkward way in which the poor creature picked up the nuts. His padded\\nhands were so clumsy and the nuts were so small that he dropped almost\\nas many as he put in the basket. But the Scarecrow did not mind how\\nlong it took him to fill the basket, for it enabled him to keep away\\nfrom the fire, as he feared a spark might get into his straw and burn\\nhim up. So he kept a good distance away from the flames, and only came\\nnear to cover Dorothy with dry leaves when she lay down to sleep. These\\nkept her very snug and warm, and she slept soundly until morning.\\n\\nWhen it was daylight, the girl bathed her face in a little rippling\\nbrook, and soon after they all started toward the Emerald City.\\n\\nThis was to be an eventful day for the travelers. They had hardly been\\nwalking an hour when they saw before them a great ditch that crossed\\nthe road and divided the forest as far as they could see on either\\nside. It was a very wide ditch, and when they crept up to the edge and\\nlooked into it they could see it was also very deep, and there were\\nmany big, jagged rocks at the bottom. The sides were so steep that none\\nof them could climb down, and for a moment it seemed that their journey\\nmust end.\\n\\n“What shall we do?” asked Dorothy despairingly.\\n\\n“I haven’t the faintest idea,” said the Tin Woodman, and the Lion shook\\nhis shaggy mane and looked thoughtful.\\n\\nBut the Scarecrow said, “We cannot fly, that is certain. Neither can we\\nclimb down into this great ditch. Therefore, if we cannot jump over it,\\nwe must stop where we are.”\\n\\n“I think I could jump over it,” said the Cowardly Lion, after measuring\\nthe distance carefully in his mind.' metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(book_texts[31])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced729ba",
   "metadata": {},
   "source": [
    "### Pinecone and OpenAI Embedding setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec5c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone related setup\n",
    "\n",
    "pinecone.init(\n",
    "        api_key = PINECONE_API_KEY,\n",
    "        environment = PINECONE_ENV\n",
    ")\n",
    "\n",
    "# Set the index name for this project in pinecone first\n",
    "\n",
    "index_name = 'testsearchbook'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacf9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40557b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pinecone.list_indexes():\n",
    "    print(\"Index does not exist: \", index_name)\n",
    "\n",
    "\n",
    "book_docsearch = Pinecone.from_texts([t.page_content for t in book_texts], embeddings, index_name = index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58ef6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.vectorstores.pinecone.Pinecone"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book_docsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3601e",
   "metadata": {},
   "source": [
    "### Import  load_qa_chain from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c59e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "121f427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the llm model for our qa session\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4093903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up the query \n",
    "\n",
    "query = \"Who is Dorothy?\"\n",
    "docs = book_docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959007c8",
   "metadata": {},
   "source": [
    "### Ask questions to your document and get the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b4b794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dorothy is a young girl who was carried away by a cyclone from her home. She is innocent and harmless and has never killed anything in her life.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the QA chain with your query to get the answer\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c0a89",
   "metadata": {},
   "source": [
    "## We can also query our own PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d836ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PDF Loader and load the file\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../data/Scale-Zeitgeist-AI-Readiness-Report-2023.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "121be12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.document_loaders.pdf.PyPDFLoader"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a353d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d2053ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b792ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "766f3fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Scale 28 29 Zeitgeist: 2023 AI Readiness ReportLogistics and Supply Chain\\nLogistics and supply chain com -\\npanies adopt AI to help them \\nimprove operational eﬃciency, \\nimprove customer experience, and \\ngrow revenue.\\nTo help achieve these goals, \\nlogistics and supply chain com -\\npanies are looking to adopt AI for \\nbetter inventory management and \\ndemand forecasting, improved \\nroute optimization, to deploy au -\\ntonomous vehicles, and improve \\ndocument processing throughput \\nand quality. These tools directly \\nimpact operational eﬃciency, \\nwhich has downstream impacts on \\nthe overall customer experience, \\nwith reliable delivery and fewer \\ndelays.\\nFor inventory management and \\ndemand forecasting, logistics \\nand supply chain companies are \\nadopting AI to help reduce costs, \\nimprove customer satisfaction, \\nand improve forecast accuracy.TOP USE CASES BY INDUSTRYLogistics and Supply Chain\\nFor route planning, logistics and \\nsupply chain companies believe AI \\ncan help improve eﬃciency, reduce \\ncosts, improve delivery accuracy, \\nand reduce shipping times. This \\ndirectly translates to improved \\noperational eﬃciency and a better \\ncustomer experience while indirect -\\nly translating to revenue growth.\\nFor document processing, logistics \\nand supply chain companies look \\nto AI to help them with informa -\\ntion processing, document clas -\\nsiﬁcation, and compliance. This \\napplication is strictly dedicated to \\nincreasing operational eﬃciency \\nand reducing costs.\\nLogistics and supply chain com -\\npanies process a lot of paperwork. \\nTo improve operational eﬃciency, \\nthis paperwork must be pro -\\ncessed as quickly and accurately \\nas possible. Logistics documents, \\nsuch as bills of lading, commercial \\ninvoices, and packing lists are full \\nof critical information required to \\nclear shipments past customs and \\nonto warehouses for distribution. \\nTraditional OCR applications re -\\nquire the creation of templates for \\neach type of document, which is \\ninfeasible and ineﬃcient for global \\nlogistics companies. Instead, these \\ncompanies rely on machine-learn -\\ning-powered document process -\\ning, which requires no templates \\nand still processes the documents \\nat over over 95% accuracy.TOP USE CASES BY INDUSTRY', metadata={'source': '../data/Scale-Zeitgeist-AI-Readiness-Report-2023.pdf', 'page': 15})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c95f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_texts = text_splitter.split_documents(file_content)\n",
    "print (len(book_texts))\n",
    "type(book_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3090e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Enterprises are mostly looking to leverage open-source generative models (41%) or Cloud API generative models (37%), while very few are looking to build their own generative models (22%). Furthermore, 28% are exclusively using open-source models, while 26% use cloud APIs and only 15% are exclusively building their own.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's set up the query \n",
    "\n",
    "query = \"How are enterprises working with generative ai?\"\n",
    "docs = book_docsearch.similarity_search(query)\n",
    "\n",
    "# Run the QA chain with your query to get the answer\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dcfc0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Companies adopting AI are seeing positive outcomes from improved customer experiences, the ability to develop new products or services and improve existing products, and improved collaboration across business functions.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's set up a different query \n",
    "\n",
    "query = \"What outcomes have companies seen from AI adoption?\"\n",
    "docs = book_docsearch.similarity_search(query)\n",
    "\n",
    "# Run the QA chain with your query to get the answer\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
